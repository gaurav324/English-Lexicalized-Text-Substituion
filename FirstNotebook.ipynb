{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "import operator\n",
      "\n",
      "from copy import deepcopy\n",
      "from gensim import utils, matutils\n",
      "from gensim.models import word2vec\n",
      "from nltk.corpus import wordnet as wn\n",
      "from nltk.tag import pos_tag\n",
      "from nltk.tokenize import word_tokenize\n",
      "from numpy import dot, multiply, add"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = word2vec.Word2Vec.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.pos_tag(nltk.word_tokenize(\"he is a good boyt\"))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 62,
       "text": [
        "[('he', 'PRP'), ('is', 'VBZ'), ('a', 'DT'), ('good', 'JJ'), ('boyt', 'NN')]"
       ]
      }
     ],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "important_tags = ['NN', 'NNS', 'VB', 'VBP', 'VBG', 'VBD', 'NNP', 'JJ', 'JJR', 'RB', 'N', 'PRP$', 'PRP', 'WDT']\n",
      "\n",
      "def get_imp_words(sentence):\n",
      "    tokens = filter(lambda x: x != -1, map(lambda x: x[0] if x[1] in important_tags else -1, nltk.pos_tag(nltk.word_tokenize(sentence))))\n",
      "    return tokens\n",
      "\n",
      "def cosine(ww1, ww2):\n",
      "    return dot(matutils.unitvec(ww1), matutils.unitvec(ww2))\n",
      "\n",
      "def get_wordnet_pos(treebank_tag):\n",
      "    if treebank_tag.startswith('J'):\n",
      "        return [wn.ADJ, wn.ADJ_SAT]\n",
      "    elif treebank_tag.startswith('V'):\n",
      "        return [wn.VERB]\n",
      "    elif treebank_tag.startswith('N'):\n",
      "        return [wn.NOUN]\n",
      "    elif treebank_tag.startswith('R'):\n",
      "        return [wn.ADV]\n",
      "    else:\n",
      "        return ''\n",
      "\n",
      "def getPosTag(sentence, word):\n",
      "    tags = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
      "    for x in tags:\n",
      "        if x[0] == word:\n",
      "            return get_wordnet_pos(x[1])\n",
      "\n",
      "def vector_op(a, b):\n",
      "    return multiply(a, b)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def replace(sentence, word):\n",
      "    sentence = sentence.lower()\n",
      "    if word not in sentence:\n",
      "        return word + \" is not found in sentence\"\n",
      "    \n",
      "    # Get the context words.\n",
      "    imp_words = get_imp_words(sentence)\n",
      "    index = imp_words.index(word)\n",
      "    \n",
      "    left = index - 0 if index - 0 >= 0 else 0\n",
      "    right = index + 2 if index + 2 <= len(imp_words) else len(imp_words)\n",
      "    \n",
      "    context_words = imp_words[left:index] + imp_words[index+1:right]\n",
      "    print context_words\n",
      "     \n",
      "    # Find unified vector.\n",
      "    word_vector = model.syn0[model.vocab[word].index]\n",
      "    base_unison = None\n",
      "    for w in context_words:\n",
      "        try:\n",
      "            if base_unison is None:\n",
      "                base_unison = deepcopy(model.syn0[model.vocab[w].index])\n",
      "            else:\n",
      "                base_unison = vector_op(base_unison, model.syn0[model.vocab[w].index])\n",
      "        except KeyError, ex:\n",
      "            print \"Warning: \" + w + \" is not in entire corpus\" \n",
      "            pass\n",
      "    ww1 = vector_op(base_unison, word_vector)\n",
      "    #ww1 = word_vector\n",
      "    \n",
      "    synset_avg = {}\n",
      "    synset_results = {}\n",
      "    \n",
      "    synsets = wn.synsets(word)\n",
      "    for synset in synsets:\n",
      "        #print sentence, word, getPosTag(sentence, word), synset.pos\n",
      "        if synset.pos not in getPosTag(sentence, word):\n",
      "            continue\n",
      "        avg = 0.0\n",
      "        replacements = synset.lemma_names\n",
      "        #print synset, replacements\n",
      "        try:\n",
      "            replacements.remove(word)\n",
      "        except ValueError:\n",
      "            pass\n",
      "        \n",
      "        remove_these = []\n",
      "        for replacement in replacements:\n",
      "            try:\n",
      "                if (model.vocab[replacement]):\n",
      "                    x = 1\n",
      "            except KeyError:\n",
      "                remove_these.append(replacement)\n",
      "        for x in remove_these:\n",
      "            replacements.remove(x)\n",
      "            \n",
      "        if len(replacements) == 0:\n",
      "            continue\n",
      "        for replacement in replacements:\n",
      "            if word in replacement or replacement in word:\n",
      "                continue\n",
      "            replacement_vector = model.syn0[model.vocab[replacement].index]\n",
      "            ww2 = vector_op(base_unison, replacement_vector)\n",
      "            synset_results[replacement] = cosine(ww1, ww2)\n",
      "            avg += synset_results[replacement]\n",
      "        avg /= len(replacements)\n",
      "        synset_avg[synset] = avg\n",
      "    \n",
      "#     for synset in sorted(synset_avg):\n",
      "#         print synset.lemma_names, synset_avg[synset]\n",
      "        \n",
      "    #print model.most_similar(word, topn=15)\n",
      "    overall_results = {}\n",
      "    for dis_sim_replacement, xx in model.most_similar(word, topn=30):\n",
      "        dis_sim_replacement = dis_sim_replacement.lower()\n",
      "        # Ideally should be checking for the form of verb and all.\n",
      "        if word in dis_sim_replacement or dis_sim_replacement in word:\n",
      "            continue\n",
      "        if \"_\" in dis_sim_replacement:\n",
      "            continue\n",
      "\n",
      "        replacement_vector = model.syn0[model.vocab[dis_sim_replacement].index]\n",
      "        ww2 = vector_op(base_unison, replacement_vector)\n",
      "        #overall_results[dis_sim_replacement] = .95 * cosine(ww1, ww2)\n",
      "        overall_results[dis_sim_replacement] = cosine(ww1, ww2)\n",
      "\n",
      "    #print \"******\"\n",
      "    #print map(lambda x: x[0], sorted(overall_results.iteritems(), key=operator.itemgetter(1), reverse=True))\n",
      "    print \"******\"\n",
      "    print sorted(overall_results.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
      "    print \"******\"\n",
      "    print sorted(synset_results.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "replace(\"done as a selectman by being innovative and fixing the problems we have with cash flows\", \"fixing\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['done', 'selectman', 'being', 'innovative', 'problems', 'we', 'have']\n",
        "******"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[('overhauling', 0.71713204693052401), ('reforming', 0.66579425541559711), ('remedying', 0.4179173415312839), ('repairing', 0.3674668390342693), ('rigging', 0.32373484993840712), ('rectifying', 0.28073179137608983), ('patching', 0.26840043508581535), ('mending', 0.10692383399953047), ('fixes', 0.095358593450150853), ('correcting', -0.0012738981434608776), ('fixers', -0.28005748065878322)]\n",
        "******\n",
        "[('get', 0.21498795250598368), ('fixate', 0.20970123046309941), ('mend', 0.2020025126041762), ('desex', 0.15085251030512914), ('repair', 0.011403252418497795), ('restore', -0.081270332449227739), ('fasten', -0.089890709360362628), ('bushel', -0.23084426499412974), ('posit', -0.23601997131754715), ('prepare', -0.24333163640196898), ('secure', -0.25137188328763377), ('cook', -0.26137271734145728), ('specify', -0.32242743995026535), ('limit', -0.32397942176343114), ('doctor', -0.37853020048638503), ('ready', -0.43071179832518403), ('make', -0.43508567498356199), ('determine', -0.43639607109076461), ('set', -0.46456685672126674), ('define', -0.48921230767794593), ('sterilize', -0.52077710802134858), ('situate', -0.56550665302427316), ('deposit', -0.71209120899338463)]\n"
       ]
      }
     ],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "replace(\"The market is tight right now\", \"tight\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['market', 'right', 'now']\n",
        "******"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[('looser', 0.82908519215208187), ('squeezed', 0.75252492606319232), ('te', 0.19829688080342167)]\n",
        "******\n",
        "[('miserly', 0.56945072053373103), ('stringent', 0.56130139726409389), ('close', 0.51661119347428508), ('stiff', 0.42652974213849654), ('sozzled', 0.42459385650190262), ('plastered', 0.4242939107349859), ('loaded', 0.40346412000404891), ('soaked', 0.39418593592121537), ('squiffy', 0.38606167192741458), ('cockeyed', 0.37207843280587133), ('besotted', 0.35434050910677173), ('mean', 0.30379635676916772), ('sloshed', 0.29769802918336752), ('taut', 0.28253871366867594), ('pixilated', 0.27086228784943039), ('crocked', 0.26226508758658351), ('rigorous', 0.24575806003117906), ('mingy', 0.23325858691501716), ('fuddled', 0.22858273202493115), ('blotto', 0.19367300746556296), ('nasty', 0.13688722113997226), ('compressed', 0.13281861349976759), ('pissed', 0.10724664966993336), ('wet', 0.095199355666907209), ('smashed', 0.017346318792250306), ('soused', -0.018806524528678148), ('slopped', -0.051043953236648933)]\n"
       ]
      }
     ],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "replace(\"George Robertson had appointed Shuja-ul-Mulk who was a bright boy only 12 years old and the youngest surviving son of Aman-ul-Mulk as the ruler of Chitral\", 'bright')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['boy']\n",
        "******"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[('shining', 0.60860410139193066), ('sparkle', 0.56786677593955548), ('shiny', 0.5394987247422538), ('dim', 0.52970028657543355), ('shinning', 0.51260646063388826), ('brighest', 0.48135123798809376), ('glow', 0.46931013016826062), ('rosey', 0.4503627255061835), ('bleak', 0.42369392452369736), ('rosy', 0.41115581507020743), ('vibrant', 0.39562192361512699), ('dark', 0.36111492892587482), ('glary', 0.22061053118283513)]\n",
        "******\n",
        "[('shining', 0.60860410139193066), ('shiny', 0.5394987247422538), ('brilliant', 0.41379232046159253), ('lustrous', 0.37977425711060575), ('hopeful', 0.37469358241722228), ('promising', 0.372063070602979), ('smart', 0.23702401075510221), ('undimmed', 0.23475172909065795), ('burnished', 0.20077942955259992), ('vivid', 0.1803272217248415)]\n"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "replace(\"The actual field is not much different than that of a 40mm only it is smaller and quite a bit noticeably brighter which is probably the main benefit\", \"brighter\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['quite', 'bit', 'noticeably', 'which', 'probably']\n",
        "******"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[('gloomier', 0.86185800767282406), ('dimmer', 0.85027672769685969), ('bluer', 0.82454012764532814), ('bleaker', 0.80086717152597364), ('cloudier', 0.78451296598989351), ('redder', 0.73823546694884956), ('blacker', 0.73776518017536663), ('livelier', 0.72545009664198146), ('kinder', 0.718441942165013), ('brightening', 0.71761767902431739), ('grimmer', 0.68175995888492236), ('rosier', 0.66585791563752916), ('dim', 0.65675920887437922), ('cheerier', 0.64970455395023152), ('better', 0.63952647303850785), ('happier', 0.63003321647806287), ('duller', 0.61631185071953853), ('sunnier', 0.58951214397785057), ('rosy', 0.56627310299160982), ('brightens', 0.56202098689813573), ('brighten', 0.5577341043155738), ('clearer', 0.52023149575798355), ('darker', 0.51131360593151132), ('prettier', 0.41000453818118943), ('brightened', 0.32500146167920696), ('gloomy', 0.31552626265464767), ('bleak', 0.31168697979205773)]\n",
        "******\n",
        "[('shining', 0.57025937976931651), ('shiny', 0.48216302569266173), ('lustrous', 0.37470240454012804), ('undimmed', 0.32986831553462836), ('vivid', 0.15662835975471623), ('burnished', 0.13490876640573454), ('hopeful', 0.091715979384719801), ('promising', -0.017233276721951338), ('brilliant', -0.057271071626688541), ('smart', -0.21452916061804056)]\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "replace(\"Snow covered areas appear bright blue in the image which was taken in early spring and shows\", \"bright\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['covered', 'areas', 'appear', 'blue', 'image']\n",
        "******"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[('shining', 0.80415313055329518), ('shinning', 0.7223144094242604), ('glary', 0.69767691383958141), ('dim', 0.6830890879195326), ('glow', 0.67813641668790481), ('sparkle', 0.63789332073757754), ('rosey', 0.63574972196908086), ('dark', 0.62724981430327753), ('bleak', 0.61162725401354012), ('rosy', 0.56645402869948491), ('shiny', 0.53320823571944076), ('vibrant', 0.48157901884893051), ('brighest', 0.44223840084356653)]\n",
        "******\n",
        "[('shining', 0.80415313055329518), ('shiny', 0.53320823571944076), ('undimmed', 0.36071617193323569), ('vivid', 0.35233455402286767), ('promising', 0.31300967634424604), ('burnished', 0.28810085619639947), ('lustrous', 0.22739234311830378), ('hopeful', 0.091129908801794474), ('brilliant', 0.059298602420073454), ('smart', -0.13902513355731688)]\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "replace(\"There are sound reasons for concluding that the long-run picture remains bright and even recent signals about the current course of the economy\", \"bright\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['concluding', 'long-run', 'picture', 'even', 'recent']\n",
        "Warning: long-run is not in entire corpus\n",
        "******"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[('dim', 0.65441372816589627), ('rosey', 0.60265127270988395), ('brighest', 0.57333407450312124), ('shiny', 0.53084341599606266), ('dark', 0.52213179478179605), ('bleak', 0.51568516370118478), ('sparkle', 0.48252406375890217), ('rosy', 0.47932958379518864), ('glow', 0.47223875536907656), ('glary', 0.37610919427527095), ('shinning', 0.27696504866034527), ('vibrant', 0.20635700281824088), ('shining', 0.16642196279210536)]\n",
        "******\n",
        "[('shiny', 0.53084341599606266), ('vivid', 0.37629685150929326), ('lustrous', 0.30251582093803936), ('smart', 0.28520026316925912), ('brilliant', 0.27349517654300431), ('promising', 0.22848966081417593), ('burnished', 0.19724368287275595), ('hopeful', 0.18671400740117625), ('shining', 0.16642196279210536), ('undimmed', 0.16183493196533527)]\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "replace(\"Anyway my pants are getting tight\", \"tight\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['my', 'pants', 'are', 'getting']\n",
        "******"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[('squeezed', 0.73403144418969324), ('looser', 0.50661987399153363), ('te', 0.18405622651094422)]\n",
        "******\n",
        "[('plastered', 0.61552150099318259), ('stringent', 0.60990865074493972), ('pixilated', 0.53932559422782633), ('mean', 0.5367055763835421), ('soaked', 0.4575284354435879), ('miserly', 0.42152659655141977), ('stiff', 0.40495317399487363), ('compressed', 0.38875721802837643), ('taut', 0.38170158287619832), ('loaded', 0.36333584736631924), ('crocked', 0.34620115653116418), ('sozzled', 0.26557233083076104), ('close', 0.21778567365986054), ('squiffy', 0.2100548107093031), ('pissed', 0.15495163416744998), ('nasty', 0.13687671408262181), ('slopped', 0.055805137313270414), ('smashed', 0.05472809697485382), ('besotted', 0.033731130210870132), ('cockeyed', 0.027097768671595135), ('wet', 0.0061005859325820311), ('mingy', -0.070120418881596813), ('soused', -0.12389461960364839), ('fuddled', -0.1528819971670024), ('rigorous', -0.19851209293172598), ('blotto', -0.22859230279807186), ('sloshed', -0.23650476578702032)]\n"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.most_similar('fixing')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 54,
       "text": [
        "[('fix', 0.5858608484268188),\n",
        " ('fixing_scandal', 0.5351758003234863),\n",
        " ('Fixing', 0.5333883762359619),\n",
        " ('Aqil_Ibrahim', 0.5322956442832947),\n",
        " ('repairing', 0.5232107639312744),\n",
        " ('reselling_foreclosed_properties', 0.4760623276233673),\n",
        " ('collusive_tendering', 0.47277069091796875),\n",
        " ('Christopher_Cadaret', 0.4637501835823059),\n",
        " ('rectifying', 0.4593717157840729),\n",
        " ('correcting', 0.4368429183959961)]"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}