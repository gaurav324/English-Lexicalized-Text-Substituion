{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from composes.semantic_space.space import Space\n",
      "from composes.transformation.scaling.ppmi_weighting import PpmiWeighting\n",
      "from composes.transformation.dim_reduction.svd import Svd\n",
      "from composes.transformation.feature_selection.top_feature_selection import TopFeatureSelection\n",
      "from composes.similarity.cos import CosSimilarity\n",
      "from composes.similarity.dot_prod import DotProdSimilarity\n",
      "from composes.similarity.lin import LinSimilarity\n",
      "from composes.utils import io_utils\n",
      "from composes.utils import log_utils\n",
      "\n",
      "import spaceInherit\n",
      "from spaceInherit import MySpace\n",
      "\n",
      "import nltk\n",
      "from nltk.tag import pos_tag\n",
      "from nltk.tokenize import word_tokenize\n",
      "\n",
      "import operator\n",
      "from copy import deepcopy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 132
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "argv = ['/Users/gnanda/nlp/final_project/English-Lexicalized-Text-Substituion', '150'];\n",
      "data_path = argv[0] + \"/\" + argv[1] + \"_\"\n",
      "\n",
      "log_file = data_path + \"all.log\"\n",
      "core_cooccurrence_file = data_path + \"matrix_file_pos\"\n",
      "core_row_file = data_path + \"row_file_pos\"\n",
      "core_col_file = data_path + \"col_file_pos\"\n",
      "core_space_file = data_path + \"core.pkl\"\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 183
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "core_space = MySpace.xbuild(data=core_cooccurrence_file, rows=core_row_file, cols=core_col_file, format=\"sm\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Progress...1000000\n",
        "Progress...2000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...3000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...4000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...5000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...6000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...7000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...8000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...9000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...10000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...11000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...12000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...13000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...14000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...15000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...16000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...17000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...18000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...19000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...20000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...21000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...22000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...23000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...24000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...25000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...26000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...27000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...28000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...29000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...30000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...31000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...32000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...33000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...34000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...35000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...36000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...37000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...38000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...39000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...40000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...41000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...42000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...43000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...44000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...45000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 184
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "core_space_ppmi = core_space.apply(PpmiWeighting())\n",
      "core_space_ppmi_top_feature = core_space.apply(TopFeatureSelection(5000))\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 185
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "important_tags = ['NN', 'NNS', 'VB', 'VBP', 'VBG', 'VBD', 'NNP', 'JJ', 'JJR', 'RB', 'N', 'PRP$', 'PRP', 'WDT']\n",
      "\n",
      "final_model = core_space_ppmi\n",
      "#final_model = final_model.apply(Svd(100))\n",
      "\n",
      "def get_imp_words(sentence):\n",
      "    tokens = filter(lambda x: x != -1, map(lambda x: x[0] if x[1] in important_tags else -1, nltk.pos_tag(nltk.word_tokenize(sentence))))\n",
      "    return tokens\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 186
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dot_sim = DotProdSimilarity()\n",
      "lin_sim = LinSimilarity()\n",
      "cos_sim = CosSimilarity()\n",
      "sim = cos_sim\n",
      "print nltk.pos_tag(nltk.word_tokenize(\"done as a selectman by being innovative and fixing the problems we have with cash flows\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('done', 'NN'), ('as', 'IN'), ('a', 'DT'), ('selectman', 'NN'), ('by', 'IN'), ('being', 'VBG'), ('innovative', 'JJ'), ('and', 'CC'), ('fixing', 'VBG'), ('the', 'DT'), ('problems', 'NNS'), ('we', 'PRP'), ('have', 'VBP'), ('with', 'IN'), ('cash', 'NN'), ('flows', 'NNS')]\n"
       ]
      }
     ],
     "prompt_number": 187
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def replace_actual(sentence, word, mul=False):\n",
      "    print sentence, word\n",
      "    # Get the context words. \n",
      "    imp_words = filter(lambda x: len(x)>2, get_imp_words(sentence))\n",
      "    index = imp_words.index(word)\n",
      "    \n",
      "    left = index - 2 if index - 2 >= 0 else 0\n",
      "    right = index + 0 if index + 0 <= len(imp_words) else len(imp_words)\n",
      "    \n",
      "    context_words = imp_words[left:index] + imp_words[index+1:right]\n",
      "    print context_words\n",
      "    \n",
      "    base_unison = None\n",
      "    for x in context_words:\n",
      "        try:\n",
      "            if base_unison is None:\n",
      "                base_unison = deepcopy(final_model.get_row(x))\n",
      "            else:\n",
      "                if mul:\n",
      "                    base_unison = base_unison.multiply(final_model.get_row(x))\n",
      "                else:\n",
      "                    base_unison += final_model.get_row(x)\n",
      "        except KeyError, ex:\n",
      "            print \"Warning: \" + x + \" is not in entire corpus\" \n",
      "            pass\n",
      "    \n",
      "    if mul:\n",
      "        z2 = base_unison.multiply(final_model.get_row(word))\n",
      "    else:\n",
      "        z2 = base_unison + final_model.get_row(word)\n",
      "\n",
      "    results = {}\n",
      "    for replacement, xx in final_model.get_neighbours(word, 100, cos_sim):\n",
      "            if replacement in context_words:\n",
      "                continue\n",
      "            if word in replacement or replacement in word:\n",
      "                continue\n",
      "            if replacement[-1] != word[-1]:\n",
      "                continue\n",
      "            \n",
      "            replacement_vector = final_model.get_row(replacement)\n",
      "            \n",
      "            if mul:\n",
      "                z1 = base_unison.multiply(replacement_vector)\n",
      "            else:\n",
      "                z1 =  base_unison + replacement_vector\n",
      "            \n",
      "            results[replacement] = cos_sim.get_sim(z1, z2)\n",
      "\n",
      "    print sorted(results.iteritems(), key=operator.itemgetter(1), reverse=True)[:30]\n",
      "\n",
      "def replace(sentence, word, mul=False):\n",
      "    sentence = sentence.lower()\n",
      "    if word not in sentence:\n",
      "        return word + \" is not found in sentence\"\n",
      "    \n",
      "    sentence = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
      "    n_s = []\n",
      "    for x,y in sentence:\n",
      "        if (x == word):\n",
      "            word = word + \"_\" + y[0].lower()\n",
      "        if y in important_tags:\n",
      "            n_s.append(x + \"_\" + y[0].lower())\n",
      "    sentence = \" \".join(n_s)\n",
      "    return replace_actual(sentence, word, mul)    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 219
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "replace(\"done as a selectman by being innovative and fixing the problems we have with cash flows\", \"fixing\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyError",
       "evalue": "'fixing_v'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-203-c2c1f2999f11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"done as a selectman by being innovative and fixing the problems we have with cash flows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fixing\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-202-93aefdba0252>\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(sentence, word)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mn_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mreplace_actual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-202-93aefdba0252>\u001b[0m in \u001b[0;36mreplace_actual\u001b[0;34m(sentence, word)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mz2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_unison\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;31m#z2 = base_unison.multiply(final_model.get_row(word))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/gnanda/anaconda/python.app/Contents/lib/python2.7/site-packages/dissect-0.1.0-py2.7.egg/composes/semantic_space/space.pyc\u001b[0m in \u001b[0;36mget_row\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfound\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \"\"\"\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcooccurrence_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow2id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyError\u001b[0m: 'fixing_v'"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['being_v', 'innovative_j', 'problems_n', 'we_p']\n",
        "Warning: being_v is not in entire corpus\n",
        "Warning: we_p is not in entire corpus\n"
       ]
      }
     ],
     "prompt_number": 203
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "replace(\"The market is tight right now\", \"tight\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "market_n tight_j right_n now_r tight_j\n",
        "['market_n']\n",
        "[('baggy_j', 0.66457380189577042), ('wide_j', 0.59051925109383163), ('intricate_j', 0.58676016449718282), ('flexible_j', 0.58397565011034713), ('horizontal_j', 0.58182268072298193), ('outer_j', 0.5808935283751776), ('loose_j', 0.57852213093471405), ('rigid_j', 0.57787053096178143), ('straight_j', 0.57587957617562202), ('narrow_j', 0.57036946826366008), ('smooth_j', 0.54820067411940798), ('purple_j', 0.54178778425785523), ('long_j', 0.53847203331988092), ('distinctive_j', 0.52764550375805086), ('thin_j', 0.52280935360865066), ('thick_j', 0.51722003703322905), ('yellow_j', 0.5154336424513517), ('red_j', 0.49968817708292479), ('white_j', 0.49611936825133895), ('black_j', 0.49384117519657716)]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 221
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "replace(\"The market is tight right now\", \"tight\", True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "market_n tight_j right_n now_r tight_j\n",
        "['market_n']\n",
        "[('thick_j', 0.17805693629260372), ('smooth_j', 0.15266805001005537), ('flexible_j', 0.1463694893508716), ('rigid_j', 0.1453162321154719), ('loose_j', 0.1409249722095664), ('straight_j', 0.13248454595481152), ('narrow_j', 0.12894275741111327), ('intricate_j', 0.11531853889811888), ('wide_j', 0.10265791579905349), ('thin_j', 0.096765149650646365), ('outer_j', 0.094404403496773259), ('horizontal_j', 0.0822969387549526), ('black_j', 0.081985422148073028), ('purple_j', 0.07894389053787973), ('baggy_j', 0.076822723706449048), ('white_j', 0.075433157386970776), ('distinctive_j', 0.070553925185121893), ('long_j', 0.069272797152120896), ('yellow_j', 0.051165797262595472), ('red_j', 0.04648303161479081)]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 220
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "replace(\"done as a selectman by being innovative and fixing the problems we have with cash flows\", \"fixing\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['being', 'innovative', 'problems', 'have']\n",
        "[('experiences', 0.99608922647430265), ('respect', 0.99308263662228502), ('forth', 0.99141953987594944), ('ruin', 0.98606787811814289), ('account', 0.98572354795430894), ('frequently', 0.98372685863110043), ('detail', 0.97479933996049106), ('favor', 0.96770086412724221), ('escape', 0.96560006299460099), ('basis', 0.96118365144254003), ('well', 0.95957676040132378), ('overcome', 0.95588442857677491), ('trait', 0.95364705985561093), ('reference', 0.94467617060640485), ('notably', 0.93877846824774347)]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 151
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "core_space_ppmi.get_neighbours(\"tight\", 30, cos_sim)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 159,
       "text": [
        "[('tight', 1.0),\n",
        " ('tighter', 0.17713323291838842),\n",
        " ('loose', 0.14313080180327181),\n",
        " ('wearing', 0.12648839327198041),\n",
        " ('wear', 0.12301257730401927),\n",
        " ('tightly', 0.11948040499178468),\n",
        " ('pants', 0.11672073211098592),\n",
        " ('sleeves', 0.11593835801787834),\n",
        " ('wore', 0.11160135829998931),\n",
        " ('jeans', 0.11139513493603249),\n",
        " ('skirt', 0.10994652379138896),\n",
        " ('waist', 0.10951629523334291),\n",
        " ('trousers', 0.10693758375799829),\n",
        " ('neck', 0.10614298192325344),\n",
        " ('shirt', 0.10576233248529197),\n",
        " ('narrow', 0.10400924784966294),\n",
        " ('baggy', 0.10357880409790393),\n",
        " ('shorts', 0.1033644596253756),\n",
        " ('fitting', 0.10229754387846383),\n",
        " ('inside', 0.10144152580794777),\n",
        " ('leather', 0.10128362012182855),\n",
        " ('jacket', 0.10070231828651716),\n",
        " ('length', 0.10015486690086937),\n",
        " ('strap', 0.10009435244883327),\n",
        " ('fit', 0.099646652975498295),\n",
        " ('black', 0.098894446139908623),\n",
        " ('legs', 0.098214114676008074),\n",
        " ('matching', 0.097944126619639998),\n",
        " ('shirts', 0.097639957528594043),\n",
        " ('cut', 0.097522845096175245)]"
       ]
      }
     ],
     "prompt_number": 159
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "core_space_ppmi.get_neighbours(\"bright\", 30, cos_sim)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 182,
       "text": [
        "[('bright', 1.0),\n",
        " ('yellow', 0.21713492392894984),\n",
        " ('red', 0.19552465260064833),\n",
        " ('blue', 0.19139015846786284),\n",
        " ('orange', 0.18779112531629233),\n",
        " ('dark', 0.18718751474398271),\n",
        " ('green', 0.18688322572963689),\n",
        " ('pink', 0.18153638913637821),\n",
        " ('pale', 0.17691779192363841),\n",
        " ('purple', 0.17434502472987876),\n",
        " ('color', 0.17139333262079573),\n",
        " ('reddish', 0.16929017489399883),\n",
        " ('colors', 0.16894133532224218),\n",
        " ('light', 0.16832171317870456),\n",
        " ('yellowish', 0.16610792796609208),\n",
        " ('white', 0.16453545345901968),\n",
        " ('greenish', 0.16230067860404973),\n",
        " ('brown', 0.16192169703125731),\n",
        " ('brighter', 0.1589892497417188),\n",
        " ('black', 0.14919554992795489),\n",
        " ('coloration', 0.14682264001298065),\n",
        " ('brightly', 0.1434475813477924),\n",
        " ('bluish', 0.14284822528461319),\n",
        " ('underparts', 0.14273101202146612),\n",
        " ('metallic', 0.14237977033460103),\n",
        " ('translucent', 0.14105261302294936),\n",
        " ('eyes', 0.14036088084895815),\n",
        " ('darker', 0.14024067999057491),\n",
        " ('colorful', 0.13992390515795389),\n",
        " ('lights', 0.13863693407768296)]"
       ]
      }
     ],
     "prompt_number": 182
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "core_space_ppmi.get_sim('correct', 'fix', cos_sim)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 181,
       "text": [
        "0.098622572055601029"
       ]
      }
     ],
     "prompt_number": 181
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}