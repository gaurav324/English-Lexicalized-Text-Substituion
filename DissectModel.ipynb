{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from composes.semantic_space.space import Space\n",
      "from composes.transformation.scaling.ppmi_weighting import PpmiWeighting\n",
      "from composes.transformation.dim_reduction.svd import Svd\n",
      "from composes.transformation.feature_selection.top_feature_selection import TopFeatureSelection\n",
      "from composes.similarity.cos import CosSimilarity\n",
      "from composes.utils import io_utils\n",
      "from composes.utils import log_utils\n",
      "\n",
      "import spaceInherit\n",
      "from spaceInherit import MySpace\n",
      "\n",
      "import nltk\n",
      "from nltk.tag import pos_tag\n",
      "from nltk.tokenize import word_tokenize\n",
      "\n",
      "from copy import deepcopy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "argv = ['/Users/gnanda/nlp/final_project/English-Lexicalized-Text-Substituion', '70'];\n",
      "data_path = argv[0] + \"/\" + argv[1] + \"_\"\n",
      "\n",
      "log_file = data_path + \"all.log\"\n",
      "core_cooccurrence_file = data_path + \"GemmaData_sm\"\n",
      "core_row_file = data_path + \"GemmaData_rows\"\n",
      "core_col_file = data_path + \"GemmaData_cols\"\n",
      "core_space_file = data_path + \"core.pkl\"\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "core_space = MySpace.xbuild(data=core_cooccurrence_file, rows=core_row_file, cols=core_col_file, format=\"sm\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Progress...1000000\n",
        "Progress...2000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...3000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...4000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...5000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...6000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...7000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...8000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...9000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...10000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...11000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...12000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...13000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...14000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...15000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...16000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...17000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...18000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...19000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...20000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...21000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...22000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...23000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...24000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...25000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...26000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...27000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...28000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...29000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...30000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "core_space_ppmi = core_space.apply(PpmiWeighting())\n",
      "core_space_ppmi_top_feature = core_space.apply(TopFeatureSelection(5000))\n",
      "\n",
      "sim = CosSimilarity()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "important_tags = ['NN', 'NNS', 'VB', 'VBP', 'VBG', 'VBD', 'NNP', 'JJ', 'JJR', 'RB', 'N', 'PRP$', 'PRP', 'WDT']\n",
      "\n",
      "final_model = core_space_ppmi_top_feature\n",
      "final_model = final_model.apply(Svd(100))\n",
      "\n",
      "def get_imp_words(sentence):\n",
      "    tokens = filter(lambda x: x != -1, map(lambda x: x[0] if x[1] in important_tags else -1, nltk.pos_tag(nltk.word_tokenize(sentence))))\n",
      "    return tokens\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print nltk.pos_tag(nltk.word_tokenize(\"done as a selectman by being innovative and fixing the problems we have with cash flows\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('done', 'NN'), ('as', 'IN'), ('a', 'DT'), ('selectman', 'NN'), ('by', 'IN'), ('being', 'VBG'), ('innovative', 'JJ'), ('and', 'CC'), ('fixing', 'VBG'), ('the', 'DT'), ('problems', 'NNS'), ('we', 'PRP'), ('have', 'VBP'), ('with', 'IN'), ('cash', 'NN'), ('flows', 'NNS')]\n"
       ]
      }
     ],
     "prompt_number": 39
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def replace(sentence, word):\n",
      "    sentence = sentence.lower()\n",
      "    if word not in sentence:\n",
      "        return word + \" is not found in sentence\"\n",
      "    \n",
      "    # Get the context words. \n",
      "    imp_words = filter(lambda x: len(x)>2, get_imp_words(sentence))\n",
      "    index = imp_words.index(word)\n",
      "    \n",
      "    left = index - 2 if index - 2 >= 0 else 0\n",
      "    right = index + 3 if index + 3 <= len(imp_words) else len(imp_words)\n",
      "    \n",
      "    context_words = imp_words[left:index] + imp_words[index+1:right]\n",
      "    print context_words\n",
      "    \n",
      "    base_unison = None\n",
      "    for x in context_words:\n",
      "        try:\n",
      "            if base_unison is None:\n",
      "                base_unison = deepcopy(final_model.get_row(x))\n",
      "            else:\n",
      "                base_unison += final_model.get_row(x)\n",
      "                #base_unison = base_unison.multiply(final_model.get_row(x))\n",
      "        except KeyError, ex:\n",
      "            print \"Warning: \" + x + \" is not in entire corpus\" \n",
      "            pass\n",
      "    \n",
      "    z2 = base_unison + final_model.get_row(word)\n",
      "    #z2 = base_unison.multiply(final_model.get_row(word))\n",
      "    \n",
      "    for replacement, xx in final_model.get_neighbours(word, 15, sim):\n",
      "            if replacement in context_words:\n",
      "                continue\n",
      "            if word in replacement or replacement in word:\n",
      "                continue\n",
      "            \n",
      "            replacement_vector = final_model.get_row(replacement)\n",
      "            z1 =  base_unison + replacement_vector\n",
      "            \n",
      "            print replacement, sim.get_sim(z1, z2)\n",
      "            "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 75
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "replace(\"done as a selectman by being innovative and fixing the problems we have with cash flows\", \"fixing\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['being', 'innovative', 'problems', 'have']\n",
        "participate"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.999976736264\n",
        "loose 0.999998261647\n",
        "collecting 0.999998336239\n",
        "set 0.99915688225\n",
        "forth 0.999993520156\n",
        "ingenuity 0.999999839414\n",
        "skill 0.999983383906\n",
        "basis 0.999901727048\n",
        "daring 0.999999785202\n",
        "driving 0.999965743189\n",
        "answering 0.99999975407\n",
        "holding 0.999928116652\n",
        "packing 0.999999822552\n",
        "carefully 0.999998460055\n"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "replace(\"The market is tight right now\", \"tight\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['market', 'right', 'now']\n",
        "abrupt"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 0.99999397439\n",
        "off 0.999996887636\n",
        "near 0.999996088872\n",
        "extreme 0.99997979309\n",
        "drift 0.999995317387\n",
        "upward 0.999994039355\n",
        "visible 0.999981573658\n",
        "rising 0.999990145906\n",
        "far 0.998509088414\n",
        "dark 0.999848688716\n",
        "pacific 0.999982428917\n",
        "lie 0.99997760478\n",
        "down 0.99972987831\n",
        "tip 0.999994779346\n"
       ]
      }
     ],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}