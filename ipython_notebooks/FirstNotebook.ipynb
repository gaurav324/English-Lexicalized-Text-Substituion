{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import nltk\n",
      "import operator\n",
      "\n",
      "from copy import deepcopy\n",
      "from gensim import utils, matutils\n",
      "from gensim.models import word2vec\n",
      "from nltk.corpus import wordnet as wn\n",
      "from nltk.tag import pos_tag\n",
      "from nltk.tokenize import word_tokenize\n",
      "from numpy import dot, multiply, add"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = word2vec.Word2Vec.load_word2vec_format('/Users/gnanda/nlp/final_project/GoogleNews-vectors-negative300.bin', binary=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nltk.pos_tag(nltk.word_tokenize(\"he is a good boyt\"))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "[('he', 'PRP'), ('is', 'VBZ'), ('a', 'DT'), ('good', 'JJ'), ('boyt', 'NN')]"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "important_tags = ['NN', 'NNS', 'VB', 'VBP', 'VBG', 'VBD', 'NNP', 'JJ', 'JJR', 'RB', 'N', 'PRP$', 'PRP', 'WDT']\n",
      "\n",
      "def get_imp_words(sentence):\n",
      "    tokens = filter(lambda x: x != -1, map(lambda x: x[0] if x[1] in important_tags else -1, nltk.pos_tag(nltk.word_tokenize(sentence))))\n",
      "    return tokens\n",
      "\n",
      "def cosine(ww1, ww2):\n",
      "    return dot(matutils.unitvec(ww1), matutils.unitvec(ww2))\n",
      "\n",
      "def get_wordnet_pos(treebank_tag):\n",
      "    if treebank_tag.startswith('J'):\n",
      "        return [wn.ADJ, wn.ADJ_SAT]\n",
      "    elif treebank_tag.startswith('V'):\n",
      "        return [wn.VERB]\n",
      "    elif treebank_tag.startswith('N'):\n",
      "        return [wn.NOUN]\n",
      "    elif treebank_tag.startswith('R'):\n",
      "        return [wn.ADV]\n",
      "    else:\n",
      "        return ''\n",
      "\n",
      "def getPosTag(sentence, word):\n",
      "    tags = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
      "    for x in tags:\n",
      "        if x[0] == word:\n",
      "            return get_wordnet_pos(x[1])\n",
      "\n",
      "def vector_op(a, b):\n",
      "    return multiply(a, b)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def replace(sentence, word):\n",
      "    sentence = sentence.lower()\n",
      "    if word not in sentence:\n",
      "        return word + \" is not found in sentence\"\n",
      "    \n",
      "    # Get the context words.\n",
      "    imp_words = get_imp_words(sentence)\n",
      "    index = imp_words.index(word)\n",
      "    \n",
      "    left = index - 1 if index - 1 >= 0 else 0\n",
      "    right = index + 3 if index + 3 <= len(imp_words) else len(imp_words)\n",
      "    \n",
      "    context_words = imp_words[left:index] + imp_words[index+1:right]\n",
      "    print context_words\n",
      "     \n",
      "    # Find unified vector.\n",
      "    word_vector = model.syn0[model.vocab[word].index]\n",
      "    base_unison = None\n",
      "    for w in context_words:\n",
      "        try:\n",
      "            if base_unison is None:\n",
      "                base_unison = deepcopy(model.syn0[model.vocab[w].index])\n",
      "            else:\n",
      "                base_unison = vector_op(base_unison, model.syn0[model.vocab[w].index])\n",
      "        except KeyError, ex:\n",
      "            print \"Warning: \" + w + \" is not in entire corpus\" \n",
      "            pass\n",
      "    ww1 = vector_op(base_unison, word_vector)\n",
      "    #ww1 = word_vector\n",
      "    \n",
      "    synset_avg = {}\n",
      "    synset_results = {}\n",
      "    \n",
      "    synsets = wn.synsets(word)\n",
      "    for synset in synsets:\n",
      "        #print sentence, word, getPosTag(sentence, word), synset.pos\n",
      "        if synset.pos not in getPosTag(sentence, word):\n",
      "            continue\n",
      "        avg = 0.0\n",
      "        replacements = synset.lemma_names\n",
      "        #print synset, replacements\n",
      "        try:\n",
      "            replacements.remove(word)\n",
      "        except ValueError:\n",
      "            pass\n",
      "        \n",
      "        remove_these = []\n",
      "        for replacement in replacements:\n",
      "            try:\n",
      "                if (model.vocab[replacement]):\n",
      "                    x = 1\n",
      "            except KeyError:\n",
      "                remove_these.append(replacement)\n",
      "        for x in remove_these:\n",
      "            replacements.remove(x)\n",
      "            \n",
      "        if len(replacements) == 0:\n",
      "            continue\n",
      "        for replacement in replacements:\n",
      "            if word in replacement or replacement in word:\n",
      "                continue\n",
      "            replacement_vector = model.syn0[model.vocab[replacement].index]\n",
      "            ww2 = vector_op(base_unison, replacement_vector)\n",
      "            synset_results[replacement] = cosine(ww1, ww2)\n",
      "            avg += synset_results[replacement]\n",
      "        avg /= len(replacements)\n",
      "        synset_avg[synset] = avg\n",
      "    \n",
      "#     for synset in sorted(synset_avg):\n",
      "#         print synset.lemma_names, synset_avg[synset]\n",
      "        \n",
      "    #print model.most_similar(word, topn=15)\n",
      "    overall_results = {}\n",
      "    for dis_sim_replacement, xx in model.most_similar(word, topn=30):\n",
      "        dis_sim_replacement = dis_sim_replacement.lower()\n",
      "        # Ideally should be checking for the form of verb and all.\n",
      "        if word in dis_sim_replacement or dis_sim_replacement in word:\n",
      "            continue\n",
      "        if \"_\" in dis_sim_replacement:\n",
      "            continue\n",
      "\n",
      "        replacement_vector = model.syn0[model.vocab[dis_sim_replacement].index]\n",
      "        ww2 = vector_op(base_unison, replacement_vector)\n",
      "        #overall_results[dis_sim_replacement] = .95 * cosine(ww1, ww2)\n",
      "        overall_results[dis_sim_replacement] = cosine(ww1, ww2)\n",
      "\n",
      "    #print \"******\"\n",
      "    #print map(lambda x: x[0], sorted(overall_results.iteritems(), key=operator.itemgetter(1), reverse=True))\n",
      "    print \"******\"\n",
      "    print sorted(overall_results.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
      "    #print \"******\"\n",
      "    print sorted(synset_results.iteritems(), key=operator.itemgetter(1), reverse=True)\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "replace(\"done as a selectman by being innovative and fixing the problems we have with cash flows\", \"fixing\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['problems']\n",
        "******"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[('remedying', 0.59781593361599827), ('fixes', 0.56469980196377156), ('rectifying', 0.55424830016623361), ('reforming', 0.54595753647001932), ('overhauling', 0.52226426816190585), ('correcting', 0.49302455303134318), ('repairing', 0.46934126747169008), ('patching', 0.4496206847615189), ('rigging', 0.4416553582052562), ('fixers', 0.41373430089953467), ('mending', 0.40558115344719198)]\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "replace(\"The market is tight right now\", \"tight\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['right']\n",
        "******"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[('squeezed', 0.49803739425503352), ('looser', 0.46420686796986854), ('te', 0.011503346045069234)]\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "replace(\"George Robertson had appointed Shuja-ul-Mulk who was a bright boy only 12 years old and the youngest surviving son of Aman-ul-Mulk as the ruler of Chitral\", 'bright')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['boy']\n",
        "******"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[('shining', 0.60860410139193066), ('sparkle', 0.56786677593955548), ('shiny', 0.5394987247422538), ('dim', 0.52970028657543355), ('shinning', 0.51260646063388826), ('brighest', 0.48135123798809376), ('glow', 0.46931013016826062), ('rosey', 0.4503627255061835), ('bleak', 0.42369392452369736), ('rosy', 0.41115581507020743), ('vibrant', 0.39562192361512699), ('dark', 0.36111492892587482), ('glary', 0.22061053118283513)]\n",
        "******\n",
        "[('shining', 0.60860410139193066), ('shiny', 0.5394987247422538), ('brilliant', 0.41379232046159253), ('lustrous', 0.37977425711060575), ('hopeful', 0.37469358241722228), ('promising', 0.372063070602979), ('smart', 0.23702401075510221), ('undimmed', 0.23475172909065795), ('burnished', 0.20077942955259992), ('vivid', 0.1803272217248415)]\n"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "replace(\"The actual field is not much different than that of a 40mm only it is smaller and quite a bit noticeably brighter which is probably the main benefit\", \"brighter\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['quite', 'bit', 'noticeably', 'which', 'probably']\n",
        "******"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[('gloomier', 0.86185800767282406), ('dimmer', 0.85027672769685969), ('bluer', 0.82454012764532814), ('bleaker', 0.80086717152597364), ('cloudier', 0.78451296598989351), ('redder', 0.73823546694884956), ('blacker', 0.73776518017536663), ('livelier', 0.72545009664198146), ('kinder', 0.718441942165013), ('brightening', 0.71761767902431739), ('grimmer', 0.68175995888492236), ('rosier', 0.66585791563752916), ('dim', 0.65675920887437922), ('cheerier', 0.64970455395023152), ('better', 0.63952647303850785), ('happier', 0.63003321647806287), ('duller', 0.61631185071953853), ('sunnier', 0.58951214397785057), ('rosy', 0.56627310299160982), ('brightens', 0.56202098689813573), ('brighten', 0.5577341043155738), ('clearer', 0.52023149575798355), ('darker', 0.51131360593151132), ('prettier', 0.41000453818118943), ('brightened', 0.32500146167920696), ('gloomy', 0.31552626265464767), ('bleak', 0.31168697979205773)]\n",
        "******\n",
        "[('shining', 0.57025937976931651), ('shiny', 0.48216302569266173), ('lustrous', 0.37470240454012804), ('undimmed', 0.32986831553462836), ('vivid', 0.15662835975471623), ('burnished', 0.13490876640573454), ('hopeful', 0.091715979384719801), ('promising', -0.017233276721951338), ('brilliant', -0.057271071626688541), ('smart', -0.21452916061804056)]\n"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "replace(\"Snow covered areas appear bright blue in the image which was taken in early spring and shows\", \"bright\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['covered', 'areas', 'appear', 'blue', 'image']\n",
        "******"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[('shining', 0.80415313055329518), ('shinning', 0.7223144094242604), ('glary', 0.69767691383958141), ('dim', 0.6830890879195326), ('glow', 0.67813641668790481), ('sparkle', 0.63789332073757754), ('rosey', 0.63574972196908086), ('dark', 0.62724981430327753), ('bleak', 0.61162725401354012), ('rosy', 0.56645402869948491), ('shiny', 0.53320823571944076), ('vibrant', 0.48157901884893051), ('brighest', 0.44223840084356653)]\n",
        "******\n",
        "[('shining', 0.80415313055329518), ('shiny', 0.53320823571944076), ('undimmed', 0.36071617193323569), ('vivid', 0.35233455402286767), ('promising', 0.31300967634424604), ('burnished', 0.28810085619639947), ('lustrous', 0.22739234311830378), ('hopeful', 0.091129908801794474), ('brilliant', 0.059298602420073454), ('smart', -0.13902513355731688)]\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "replace(\"There are sound reasons for concluding that the long-run picture remains bright and even recent signals about the current course of the economy\", \"bright\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['concluding', 'long-run', 'picture', 'even', 'recent']\n",
        "Warning: long-run is not in entire corpus\n",
        "******"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[('dim', 0.65441372816589627), ('rosey', 0.60265127270988395), ('brighest', 0.57333407450312124), ('shiny', 0.53084341599606266), ('dark', 0.52213179478179605), ('bleak', 0.51568516370118478), ('sparkle', 0.48252406375890217), ('rosy', 0.47932958379518864), ('glow', 0.47223875536907656), ('glary', 0.37610919427527095), ('shinning', 0.27696504866034527), ('vibrant', 0.20635700281824088), ('shining', 0.16642196279210536)]\n",
        "******\n",
        "[('shiny', 0.53084341599606266), ('vivid', 0.37629685150929326), ('lustrous', 0.30251582093803936), ('smart', 0.28520026316925912), ('brilliant', 0.27349517654300431), ('promising', 0.22848966081417593), ('burnished', 0.19724368287275595), ('hopeful', 0.18671400740117625), ('shining', 0.16642196279210536), ('undimmed', 0.16183493196533527)]\n"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "replace(\"Anyway my pants are getting tight\", \"tight\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "unsupported operand type(s) for *: 'NoneType' and 'float'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-15-66ae795b1968>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Anyway my pants are getting tight\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tight\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-11-53a35c32dcce>\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(sentence, word)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Warning: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" is not in entire corpus\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mww1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvector_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_unison\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;31m#ww1 = word_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-9-09da5010f73d>\u001b[0m in \u001b[0;36mvector_op\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvector_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'NoneType' and 'float'"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[]\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.most_similar('fixing', topn=30)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "[('fix', 0.5858608484268188),\n",
        " ('fixing_scandal', 0.5351758003234863),\n",
        " ('Fixing', 0.5333883762359619),\n",
        " ('Aqil_Ibrahim', 0.5322956442832947),\n",
        " ('repairing', 0.5232107639312744),\n",
        " ('reselling_foreclosed_properties', 0.4760623276233673),\n",
        " ('collusive_tendering', 0.47277069091796875),\n",
        " ('Christopher_Cadaret', 0.4637501835823059),\n",
        " ('rectifying', 0.4593717157840729),\n",
        " ('correcting', 0.4368429183959961),\n",
        " ('mending', 0.4346282482147217),\n",
        " ('bid_rigging', 0.43165186047554016),\n",
        " ('fixes', 0.42863067984580994),\n",
        " ('rigging', 0.42460209131240845),\n",
        " ('remedying', 0.42198440432548523),\n",
        " ('Sapina_brothers', 0.41762763261795044),\n",
        " ('paraffin_mafia', 0.41650670766830444),\n",
        " ('club_FK_Pobeda', 0.41535043716430664),\n",
        " ('meter_Mount_Baruntse', 0.41396182775497437),\n",
        " ('Justice_Malik_Qayyum', 0.4082905054092407),\n",
        " ('Paulo_Jose_Danelon', 0.4069775938987732),\n",
        " ('overhauling', 0.40590888261795044),\n",
        " ('reforming', 0.40557610988616943),\n",
        " ('Repairing', 0.40418973565101624),\n",
        " ('fixers', 0.40098580718040466),\n",
        " ('captain_Hansie_Cronje', 0.40058067440986633),\n",
        " ('patching', 0.39963802695274353),\n",
        " ('tractors_sewing_machines', 0.39429548382759094),\n",
        " ('Combino_trams', 0.39101642370224),\n",
        " ('powdered_laundry_detergent', 0.38728010654449463)]"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "replace(\"If we order our lives well\", \"order\") "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['we', 'our', 'lives']\n",
        "******"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "[('injuction', 0.77809456806027266), ('injunction', 0.72715940360975573), ('must', 0.70495350403697676), ('exparte', 0.45957530434340571), ('directive', 0.42660930561886135), ('necessary', 0.40846238255134554), ('forthwith', 0.15020185826047799), ('directives', 0.060201639229069084)]\n",
        "[('ordinate', 0.57043823857786458), ('grade', 0.45420416892463045), ('enjoin', 0.38700688917691273), ('place', 0.3095220844177301), ('put', 0.27457283384808373), ('range', 0.23596713918254553), ('regularize', 0.17004875379322743), ('tell', 0.050315815437827677), ('ordain', 0.03192054403351105), ('rank', -0.030750746101516735), ('rate', -0.046249365666477249), ('prescribe', -0.069255225817123428), ('arrange', -0.12916269123838603), ('say', -0.19617390380050143), ('govern', -0.26327023960207796), ('consecrate', -0.26989300899509239), ('regulate', -0.36877517334609949), ('dictate', -0.51054631168528564)]\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}