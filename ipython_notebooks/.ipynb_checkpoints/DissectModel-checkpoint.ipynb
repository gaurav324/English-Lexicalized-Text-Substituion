{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from composes.semantic_space.space import Space\n",
      "from composes.transformation.scaling.ppmi_weighting import PpmiWeighting\n",
      "from composes.transformation.dim_reduction.svd import Svd\n",
      "from composes.transformation.feature_selection.top_feature_selection import TopFeatureSelection\n",
      "from composes.similarity.cos import CosSimilarity\n",
      "from composes.similarity.dot_prod import DotProdSimilarity\n",
      "from composes.similarity.lin import LinSimilarity\n",
      "from composes.utils import io_utils\n",
      "from composes.utils import log_utils\n",
      "\n",
      "import spaceInherit\n",
      "from spaceInherit import MySpace\n",
      "\n",
      "import nltk\n",
      "from nltk.corpus import wordnet as wn\n",
      "from nltk.stem import WordNetLemmatizer\n",
      "from nltk.tag import pos_tag\n",
      "from nltk.tokenize import word_tokenize\n",
      "\n",
      "import operator\n",
      "from copy import deepcopy\n",
      "\n",
      "from composes.semantic_space.space import Space\n",
      "from composes.semantic_space.peripheral_space import PeripheralSpace\n",
      "from composes.similarity.cos import CosSimilarity\n",
      "from composes.utils import io_utils, log_utils\n",
      "import os"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "argv = ['/Users/gnanda/nlp/final_project/English-Lexicalized-Text-Substituion/data/', '150'];\n",
      "data_path = argv[0] + \"/\" + argv[1] + \"_\"\n",
      "\n",
      "log_file = data_path + \"all.log\"\n",
      "core_cooccurrence_file = data_path + \"matrix_file_pos\"\n",
      "core_row_file = data_path + \"row_file_pos\"\n",
      "core_col_file = data_path + \"col_file_pos\"\n",
      "core_space_file = data_path + \"core.pkl\"\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "core_space = MySpace.xbuild(data=core_cooccurrence_file, rows=core_row_file, cols=core_col_file, format=\"sm\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Progress...1000000\n",
        "Progress...2000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...3000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...4000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...5000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...6000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...7000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...8000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...9000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...10000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...11000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...12000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...13000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...14000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...15000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...16000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...17000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...18000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...19000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...20000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...21000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...22000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...23000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...24000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...25000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...26000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...27000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...28000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...29000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...30000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...31000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...32000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...33000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...34000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...35000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...36000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...37000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...38000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...39000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...40000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...41000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...42000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...43000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...44000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...45000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "core_space_ppmi = core_space.apply(PpmiWeighting())\n",
      "core_space_ppmi_top_feature = core_space.apply(TopFeatureSelection(5000))\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "important_tags = ['NN', 'NNS', 'VB', 'VBP', 'VBG', 'VBD', 'NNP', 'JJ', 'JJR', 'RB', 'N', 'PRP$', 'PRP', 'WDT']\n",
      "\n",
      "final_model = core_space_ppmi\n",
      "#final_model = final_model.apply(Svd(100))\n",
      "\n",
      "wnl = WordNetLemmatizer()\n",
      "\n",
      "def get_wordnet_pos(treebank_tag):\n",
      "    if treebank_tag.startswith('J'):\n",
      "        return wn.ADJ\n",
      "    elif treebank_tag.startswith('V'):\n",
      "        return wn.VERB\n",
      "    elif treebank_tag.startswith('N'):\n",
      "        return wn.NOUN\n",
      "    elif treebank_tag.startswith('R'):\n",
      "        return wn.ADV\n",
      "    else:\n",
      "        return None\n",
      "    \n",
      "def get_imp_words(sentence):\n",
      "    tokens = filter(lambda x: x != -1, map(lambda x: x[0] if x[1] in important_tags else -1, nltk.pos_tag(nltk.word_tokenize(sentence))))\n",
      "    return tokens\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 63
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dot_sim = DotProdSimilarity()\n",
      "lin_sim = LinSimilarity()\n",
      "cos_sim = CosSimilarity()\n",
      "sim = cos_sim\n",
      "print nltk.pos_tag(nltk.word_tokenize(\"done as a selectman by being innovative and fixing the problems we have with cash flows\"))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('done', 'NN'), ('as', 'IN'), ('a', 'DT'), ('selectman', 'NN'), ('by', 'IN'), ('being', 'VBG'), ('innovative', 'JJ'), ('and', 'CC'), ('fixing', 'VBG'), ('the', 'DT'), ('problems', 'NNS'), ('we', 'PRP'), ('have', 'VBP'), ('with', 'IN'), ('cash', 'NN'), ('flows', 'NNS')]\n"
       ]
      }
     ],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def replace_actual(sentence, word, mul=False):\n",
      "    print sentence, word\n",
      "    # Get the context words. \n",
      "    imp_words = filter(lambda x: len(x)>2, get_imp_words(sentence))\n",
      "    index = imp_words.index(word)\n",
      "    \n",
      "    left = index - 0 if index - 0 >= 0 else 0\n",
      "    right = index + 2 if index + 2 <= len(imp_words) else len(imp_words)\n",
      "    \n",
      "    context_words = imp_words[left:index] + imp_words[index+1:right]\n",
      "    print context_words\n",
      "    \n",
      "    base_unison = None\n",
      "    for x in context_words:\n",
      "        try:\n",
      "            if base_unison is None:\n",
      "                base_unison = deepcopy(final_model.get_row(x))\n",
      "            else:\n",
      "                if mul:\n",
      "                    base_unison = base_unison.multiply(final_model.get_row(x))\n",
      "                else:\n",
      "                    base_unison += final_model.get_row(x)\n",
      "        except KeyError, ex:\n",
      "            print \"Warning: \" + x + \" is not in entire corpus\" \n",
      "            pass\n",
      "    \n",
      "    if mul:\n",
      "        z2 = base_unison.multiply(final_model.get_row(word))\n",
      "    else:\n",
      "        z2 = base_unison + final_model.get_row(word)\n",
      "\n",
      "    results = {}\n",
      "    for replacement, xx in final_model.get_neighbours(word, 100, cos_sim):\n",
      "            if replacement in context_words:\n",
      "                continue\n",
      "            if word in replacement or replacement in word:\n",
      "                continue\n",
      "            if replacement[-1] != word[-1]:\n",
      "                continue\n",
      "            \n",
      "            replacement_vector = final_model.get_row(replacement)\n",
      "            \n",
      "            if mul:\n",
      "                z1 = base_unison.multiply(replacement_vector)\n",
      "            else:\n",
      "                z1 =  base_unison + replacement_vector\n",
      "            \n",
      "            results[replacement] = cos_sim.get_sim(z1, z2)\n",
      "\n",
      "    print sorted(results.iteritems(), key=operator.itemgetter(1), reverse=True)[:30]\n",
      "\n",
      "def replace(sentence, word, mul=False):\n",
      "    sentence = sentence.lower()\n",
      "    if word not in sentence:\n",
      "        return word + \" is not found in sentence\"\n",
      "    \n",
      "    sentence = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
      "    n_s = []\n",
      "    for x,y in sentence:\n",
      "        if (x == word):\n",
      "            pos_tag = get_wordnet_pos(y)\n",
      "            if pos_tag:\n",
      "                x = wnl.lemmatize(x, pos=pos_tag)\n",
      "            word = x + \"_\" + y[0].lower()\n",
      "        if y in important_tags:\n",
      "            n_s.append(x + \"_\" + y[0].lower())\n",
      "    sentence = \" \".join(n_s)\n",
      "    return replace_actual(sentence, word, mul)    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print final_model.get_sim('boy_n', 'yellow_j', cos_sim)\n",
      "print final_model.get_sim('boy_n', 'brilliant_j', cos_sim)\n",
      "print final_model.get_sim('boy_n', 'yellowish_j', cos_sim)\n",
      "\n",
      "print final_model.get_neighbours('brilliant_j', 10, cos_sim)\n",
      "print final_model.get_sim('bright_j', 'talented_j', cos_sim)\n",
      "print final_model.get_sim('boy_n', 'talented_j', cos_sim)\n",
      "print final_model.get_sim('bright_j', 'renowned_j', cos_sim)\n",
      "print final_model.get_sim('boy_n', 'renowned_j', cos_sim)\n",
      "print final_model.get_sim('bright_j', 'gifted_j', cos_sim)\n",
      "print final_model.get_sim('boy_n', 'gifted_j', cos_sim)\n",
      "print final_model.get_sim('bright_j', 'clever_j', cos_sim)\n",
      "print final_model.get_sim('boy_n', 'clever_j', cos_sim)\n",
      "\n",
      "print final_model.get_neighbours('yellow_j', 10, cos_sim)\n",
      "print final_model.get_sim('bright_j', 'red_j', cos_sim)\n",
      "print final_model.get_sim('boy_n', 'red_j', cos_sim)\n",
      "print final_model.get_sim('bright_j', 'blue_j', cos_sim)\n",
      "print final_model.get_sim('boy_n', 'blue_j', cos_sim)\n",
      "print final_model.get_sim('bright_j', 'white_j', cos_sim)\n",
      "print final_model.get_sim('boy_n', 'white_j', cos_sim)\n",
      "print final_model.get_sim('bright_j', 'green_j', cos_sim)\n",
      "print final_model.get_sim('boy_n', 'green_j', cos_sim)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.0770685323359\n",
        "0.0790606854057\n",
        "0.0230263398532\n",
        "[('brilliant_j', 1.0), ('talented_j', 0.18254736174297512), ('renowned_j', 0.17600682060909784), ('gifted_j', 0.17386507259091516), ('clever_j', 0.17274495590559491), ('superb_j', 0.17231877359433206), ('accomplished_j', 0.16696853830604078), ('bright_j', 0.16541326416748212), ('intelligent_j', 0.163961492432488), ('skilled_j', 0.15894194196105182)]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.074671598234\n",
        "0.0717868422956\n",
        "0.0631524285661\n",
        "0.0670557113846\n",
        "0.0494072340006\n",
        "0.0464048141515\n",
        "0.0687323761406\n",
        "0.0697324055867\n",
        "[('yellow_j', 1.0), ('red_j', 0.3590060496011363), ('blue_j', 0.34418525483772855), ('white_j', 0.33761881317978693), ('green_j', 0.32321621911562137), ('orange_j', 0.30924871096332712), ('brown_j', 0.3081059097881394), ('black_j', 0.30152576251655866), ('purple_j', 0.29819222513987986), ('pale_j', 0.28069837026715888)]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.215644991575\n",
        "0.0996021467728\n",
        "0.210008825308\n",
        "0.104492983148\n",
        "0.191249028233\n",
        "0.098572490757\n",
        "0.209938141635\n",
        "0.0860827889304\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def replace_actual(sentence, word, mul=False):\n",
      "    print sentence, word\n",
      "    # Get the context words. \n",
      "    imp_words = filter(lambda x: len(x)>2, get_imp_words(sentence))\n",
      "    index = imp_words.index(word)\n",
      "    \n",
      "    left = index - 0 if index - 0 >= 0 else 0\n",
      "    right = index + 2 if index + 2 <= len(imp_words) else len(imp_words)\n",
      "    \n",
      "    context_words = imp_words[left:index] + imp_words[index+1:right]\n",
      "    print context_words\n",
      "    \n",
      "    base_unison = None\n",
      "    for x in context_words:\n",
      "        try:\n",
      "            if base_unison is None:\n",
      "                base_unison = deepcopy(final_model.get_row(x))\n",
      "            else:\n",
      "                if mul:\n",
      "                    base_unison = base_unison.multiply(final_model.get_row(x))\n",
      "                else:\n",
      "                    base_unison += final_model.get_row(x)\n",
      "        except KeyError, ex:\n",
      "            print \"Warning: \" + x + \" is not in entire corpus\" \n",
      "            pass\n",
      "    \n",
      "    if mul:\n",
      "        z2 = base_unison.multiply(final_model.get_row(word))\n",
      "    else:\n",
      "        z2 = base_unison + final_model.get_row(word)\n",
      "\n",
      "    results = final_model.get_xneighbours(z2, 20, cos_sim)\n",
      "    \n",
      "    #print results\n",
      "    for replacement, xx in final_model.get_neighbours(word, 100, cos_sim):\n",
      "            if replacement in context_words:\n",
      "                continue\n",
      "            if word in replacement or replacement in word:\n",
      "                continue\n",
      "            if replacement[-1] != word[-1]:\n",
      "                continue\n",
      "            \n",
      "            replacement_vector = final_model.get_row(replacement)\n",
      "            \n",
      "            if mul:\n",
      "                z1 = base_unison.multiply(replacement_vector)\n",
      "            else:\n",
      "                z1 =  base_unison + replacement_vector\n",
      "            \n",
      "            results[replacement] = cos_sim.get_sim(z1, z2)\n",
      "\n",
      "    print sorted(results.iteritems(), key=operator.itemgetter(1), reverse=True)[:30]\n",
      "\n",
      "def replace(sentence, word, mul=False):\n",
      "    sentence = sentence.lower()\n",
      "    if word not in sentence:\n",
      "        return word + \" is not found in sentence\"\n",
      "    \n",
      "    sentence = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
      "    n_s = []\n",
      "    for x,y in sentence:\n",
      "        if (x == word):\n",
      "            pos_tag = get_wordnet_pos(y)\n",
      "            if pos_tag:\n",
      "                x = wnl.lemmatize(x, pos=pos_tag)\n",
      "            word = x + \"_\" + y[0].lower()\n",
      "        if y in important_tags:\n",
      "            n_s.append(x + \"_\" + y[0].lower())\n",
      "    sentence = \" \".join(n_s)\n",
      "    return replace_actual(sentence, word, mul)    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 65
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "replace(\"He is a intelligent and bright boy\", \"bright\", mul=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "he_p intelligent_n bright_j boy_n bright_j\n",
        "['boy_n']\n",
        "[('bright_j', 0.35636839311626689), ('boy_n', 0.21560296061394346), ('spongy_n', 0.11586760436573436), ('expectorated_v', 0.11577700660357106), ('colorfastness_n', 0.11445772258620433), ('sward_r', 0.10638097005139037), ('blue_j', 0.10454541900823076), ('khakis_n', 0.10233724548670611), ('snorter_n', 0.10076715690803908), ('purple_j', 0.099812310278487582), ('sleeved_j', 0.097664860163691289), ('yellow_j', 0.094274871741249641), ('minnow_r', 0.091853660212230764), ('sleeveless_j', 0.091301773795793212), ('pink_j', 0.090706337210721799), ('blonde_j', 0.089628077421200242), ('beautiful_j', 0.089456935479807403), ('brilliant_j', 0.089223689070227305), ('red_j', 0.088835350563480214), ('wear_v', 0.088614663695212745)]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print final_model.get_sim('bright_j', 'intelligent_j', cos_sim)\n",
      "print final_model.get_sim('bright_j', '_j', cos_sim)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('outdoor_n', 0.99999999999999989), ('indoor_n', 0.31881831398202765), ('indoor_j', 0.18614240859150644), ('outdoor_j', 0.18474902588612868), ('amphitheaters_n', 0.18183430714938859), ('heptathlon_n', 0.14041883649452294), ('handball_n', 0.13281955263338374), ('volleyball_n', 0.13023013060810729), ('athletics_n', 0.12684572735484584), ('hammocks_n', 0.12604977922622779), ('softball_n', 0.12366248756968094), ('lacrosse_n', 0.12326924907155022), ('badminton_n', 0.12170840639183605), ('tennis_n', 0.11929850992252701), ('equaled_n', 0.1168015355511825), ('soccer_n', 0.11671910395703526), ('netball_n', 0.11440103535489028), ('swimming_n', 0.11264218388133197), ('basketball_n', 0.11164503332287079), ('gymnastics_n', 0.10829281415142682), ('trampolining_n', 0.10803460591280296), ('educations_n', 0.1078374438239172), ('rowing_n', 0.106235524761449), ('volunteering_n', 0.10479890849046862), ('elopements_n', 0.10395298892241331), ('triathlon_n', 0.10213248365246991), ('rink_n', 0.10162578624307671), ('sports_j', 0.101568460679845), ('gymnasium_n', 0.099526751231774069), ('ballasts_n', 0.099457413990969495)]\n",
        "0.00845194416935\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "replace(\"She is a bright student\", \"bright\", True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "she_p bright_j student_n bright_j\n",
        "['she_p', 'student_n']\n",
        "[('brilliant_j', 0.3364448648592539), ('beautiful_j', 0.32855611552310321), ('attractive_j', 0.21703189056637226), ('warm_j', 0.2020957878221768), ('dark_j', 0.17057400692112357), ('dull_j', 0.14253148369955046), ('pale_j', 0.13328014884978318), ('red_j', 0.12113806542621214), ('soft_j', 0.087455989863044231), ('light_j', 0.086148736065340195), ('white_j', 0.068359197046622078), ('faint_j', 0.065561246617964156), ('black_j', 0.062167766742493025), ('bluish_j', 0.053332519945512441), ('brownish_j', 0.051115983138404), ('smooth_j', 0.048191133713315362), ('crimson_j', 0.037555756980047157), ('purple_j', 0.030099153310445624), ('glossy_j', 0.02551774438877883), ('reddish_j', 0.02446159025048986), ('pink_j', 0.024185462848021418), ('thin_j', 0.022015412065843096), ('distinctive_j', 0.021792114347155295), ('visible_j', 0.02124999422401638), ('green_j', 0.018111862457644613), ('yellow_j', 0.014632738054878325), ('vibrant_j', 0.014417036500999498), ('thick_j', 0.012301776164255006), ('blue_j', 0.012104865939130094), ('brown_j', 0.01202592390646769)]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 232
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "replace(\"The actual field is not much different than that of a 40mm only it is smaller and quite a bit noticeably brighter which is probably the main benefit\", \"brighter\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "actual_j field_n not_r much_j different_j only_r it_p smaller_j quite_r bit_n noticeably_r brighter_j which_w probably_r main_j benefit_n brighter_j\n",
        "['bit_n', 'noticeably_r', 'which_w', 'probably_r', 'main_j']\n",
        "[('bacilli_j', 0.99795687532320343), ('refashioned_j', 0.99789097647648795), ('duller_j', 0.99786195345198403), ('carroty_j', 0.99783604500912582), ('knotting_j', 0.99782967200818296), ('puppy_j', 0.99782813950365135), ('witnessing_j', 0.99778127195821653), ('skewer_j', 0.99778127195821653), ('repatriating_j', 0.99778127195821653), ('demeaning_j', 0.99778127195821653), ('warder_j', 0.99778127195821653), ('savaging_j', 0.99778127195821653), ('eatery_j', 0.99778127195821653), ('reconstituting_j', 0.99778127195821653), ('premiering_j', 0.99778127195821653), ('worthier_j', 0.99778093880181873), ('rarer_j', 0.99769989198129638), ('costlier_j', 0.99769664808566449), ('fairer_j', 0.99762423798602096), ('noisier_j', 0.99757351325894039), ('fable_j', 0.99721074480708716), ('terrifying_j', 0.99719617311830211), ('thriftiest_j', 0.99718541249002923), ('accessorizing_j', 0.99714019648536378), ('messier_j', 0.9970344121174991), ('fluorine_j', 0.99702279973028662), ('smarter_j', 0.9970170669581514), ('activating_j', 0.99697235089597003), ('darning_j', 0.9969128904232416), ('explained_j', 0.99651945043610779)]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 233
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "replace(\"Snow covered areas appear bright blue in the image which was taken in early spring and shows\", \"bright\", True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "snow_n covered_v areas_n appear_v bright_j blue_j image_n which_w was_v early_j spring_n bright_j\n",
        "['appear_v', 'blue_j']\n",
        "[('yellow_j', 0.65261152869481875), ('green_j', 0.61585583405033961), ('dark_j', 0.58857144969646957), ('light_j', 0.56862529947141016), ('bluish_j', 0.54708652195978236), ('metallic_j', 0.53480937231033132), ('dull_j', 0.5215270282758393), ('reddish_j', 0.5187521646990394), ('transparent_j', 0.51035002653774719), ('purple_j', 0.50110465667694049), ('brilliant_j', 0.48551167610924711), ('faint_j', 0.47898877294649034), ('visible_j', 0.47786510501257062), ('brown_j', 0.47087916019603182), ('pale_j', 0.46977615157267938), ('silvery_j', 0.46618600385945247), ('black_j', 0.45989867042826055), ('red_j', 0.44813113119918191), ('translucent_j', 0.44557865870420693), ('iridescent_j', 0.44299007004869756), ('glossy_j', 0.44059284421459782), ('opaque_j', 0.43980170814525782), ('pink_j', 0.43927705755806684), ('whitish_j', 0.43702509962467645), ('yellowish_j', 0.43667923523866164), ('greenish_j', 0.4337273774947224), ('buff_j', 0.42213862598101953), ('brownish_j', 0.42079559228330454), ('grayish_j', 0.41782174954365964), ('white_j', 0.41764182807253042)]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 242
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "replace(\"If we order our lives well\", \"order\", True) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "we_p order_v our_p lives_n well_r order_v\n",
        "['we_p', 'our_p', 'lives_n']\n",
        "Warning: we_p is not in entire corpus\n",
        "[('decide_v', 0.81197602433732574), ('plan_v', 0.62095648570159823), ('capture_v', 0.46751796196246065), ('instruct_v', 0.4228661085796665), ('agree_v', 0.420463061996728), ('arrive_v', 0.35608163983849633), ('return_v', 0.27895678056153134), ('send_v', 0.26367690616602119), ('escort_v', 0.24846569836678542), ('force_v', 0.23138669793249628), ('fight_v', 0.21366090891511), ('refuse_v', 0.20377768276249361), ('attack_v', 0.16542420743585853), ('compel_v', 0.14916509280795137), ('authorize_v', 0.13478373894053292), ('deploy_v', 0.13412142956003195), ('wound_v', 0.13250986236479603), ('escape_v', 0.12023158891571077), ('attempt_v', 0.10673522407086106), ('arrest_v', 0.10511703869832417), ('kill_v', 0.099207371352209833), ('prepare_v', 0.086390072118402134), ('flee_v', 0.081751946829316288), ('assign_v', 0.072958634687330451), ('lead_v', 0.072461870679480983), ('soldier_v', 0.07227355406897075), ('proceed_v', 0.067768766265289965), ('announce_v', 0.066822515742570268), ('execute_v', 0.057834003614373151), ('permit_v', 0.053522511547882207)]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 257
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "replace(\"Please compile the order\", \"order\", True) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "please_n compile_v order_n order_n\n",
        "['compile_v']\n",
        "[('authority_n', 0.30005295408226063), ('act_n', 0.26703853190011467), ('regulations_n', 0.25281489174051164), ('law_n', 0.24526910439587274), ('force_n', 0.24073072417812608), ('government_n', 0.22541069741088682), ('power_n', 0.22477515095104289), ('request_n', 0.22172784236418333), ('requirement_n', 0.21320958312162619), ('amendment_n', 0.20902151411767386), ('right_n', 0.20746706559214412), ('enforcement_n', 0.20418109418817576), ('establishment_n', 0.20399989607314378), ('purpose_n', 0.19356499479033892), ('rule_n', 0.18391828012408132), ('service_n', 0.18144130567607317), ('court_n', 0.17896892516548868), ('case_n', 0.17871253946150648), ('function_n', 0.17335382124159868), ('regulation_n', 0.17246436978054433), ('etc_n', 0.16330563420649627), ('provisions_n', 0.16225281567920147), ('property_n', 0.16130913032831479), ('responsibility_n', 0.15838952919572014), ('jurisdiction_n', 0.1545758436459358), ('rules_n', 0.15243842477188235), ('form_n', 0.1515602560932808), ('tax_n', 0.14919856688605981), ('control_n', 0.14913076661643707), ('constitution_n', 0.14807660628187735)]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 263
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "replace(\"If you are ordering several of one item , please allow us enough time to compile the ordder\", \"ordering\", True) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "'order_v' is not in list",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-275-f63e8f29c6cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"If you are ordering several of one item , please allow us enough time to compile the ordder\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ordering\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-270-d5f9d920f21d>\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(sentence, word, mul)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mn_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mreplace_actual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmul\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-270-d5f9d920f21d>\u001b[0m in \u001b[0;36mreplace_actual\u001b[0;34m(sentence, word, mul)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Get the context words.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mimp_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_imp_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimp_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mValueError\u001b[0m: 'order_v' is not in list"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "you_p are_v ordering_v several_j item_n please_n allow_n us_p enough_r time_n compile_v ordder_n order_v\n"
       ]
      }
     ],
     "prompt_number": 275
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x1 = final_model.get_row('our_p'); x2 = final_model.get_row('lives_n'); \n",
      "r1 = final_model.get_row('order_v');\n",
      "r2 = final_model.get_row('arrange_v');\n",
      "z1 = x1.multiply(x2).multiply(r1)\n",
      "z2 = x1.multiply(x2).multiply(r2)\n",
      "\n",
      "cos_sim.get_sim(z1, z2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 261,
       "text": [
        "0.20370115950072731"
       ]
      }
     ],
     "prompt_number": 261
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "final_model = io_utils.load(\"/Users/gnanda/nlp/final_project/demo/core.pkl\",\n",
      "                            Space)\n",
      "\n",
      "per_space = PeripheralSpace.build(final_model,\n",
      "                                  data=\"/Users/gnanda/nlp/final_project/demo/sv.sm\", \n",
      "                                  cols=\"/Users/gnanda/nlp/final_project/demo/sv.cols\",\n",
      "                                  rows=\"/Users/gnanda/nlp/final_project/demo/sv.rows\",\n",
      "                                  format=\"sm\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Progress...1000000\n",
        "Progress...2000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...3000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...4000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Progress...5000000"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print final_model.get_neighbours(\"bar-n\", 10, CosSimilarity())\n",
      "print final_model.get_sim(\"snack-n\", \"bar-n\", CosSimilarity())\n",
      "\n",
      "print per_space.get_neighbours(\"delivery-n_pay-v\", 10, CosSimilarity())\n",
      "print per_space.get_sim(\"delivery-n_pay-v\", \"bill-n\", CosSimilarity())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[('bar-n', 0.99999999999999878), ('restaurant-n', 0.74058014001794525), ('pub-n', 0.71611988955492001), ('drink-n', 0.67407338328953814), ('room-n', 0.64506105061157193), ('shop-n', 0.6315330900775844), ('front-n', 0.61614126091667021), ('corner-n', 0.61472778589341803), ('sit-v', 0.61471612771396222), ('relax-v', 0.61227036896428577)]\n",
        "Row string snack-n not found, returning 0.0\n",
        "0.0\n",
        "[('delivery-n_pay-v', 0.99999999999999867), ('item-n_send-v', 0.54145596886157832), ('customer-n_send-v', 0.52397275336142313), ('address-n_purchase-v', 0.51879226084033514), ('message-n_supply-v', 0.50145944147724408), ('supplier-n_send-v', 0.49510321417335384), ('request-n_collect-v', 0.48981098725219235), ('address-n_send-v', 0.48042799223989735), ('cannot-n_send-v', 0.47947746623718834), ('item-n_buy-v', 0.4756012255400397)]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Row string bill-n not found, returning 0.0\n",
        "0.0\n"
       ]
      }
     ],
     "prompt_number": 61
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}